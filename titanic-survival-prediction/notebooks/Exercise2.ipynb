{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aude Sustronck\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert your code to production-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Refactoring my code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath: str):\n",
    "    \"\"\"Loads and preprocesses the Titanic dataset.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "    \n",
    "    # Feature and target separation\n",
    "    X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "    y = df['Survived']\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Trains Logistic Regression and Random Forest models.\"\"\"\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    # Random Forest with hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    \n",
    "    return logreg, best_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions and Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(models, X_test, y_test):\n",
    "    \"\"\"Evaluates the models and prints metrics.\"\"\"\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"{model_name} Metrics:\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_pipeline(filepath: str):\n",
    "    \"\"\"Main pipeline to process data, train models, and evaluate them.\"\"\"\n",
    "    # Step 1: Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(filepath)\n",
    "    \n",
    "    # Normalize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Step 2: Train models\n",
    "    logreg, best_rf = train_model(X_train_scaled, y_train)\n",
    "    \n",
    "    # Step 3: Predict and evaluate\n",
    "    models = {\"Logistic Regression\": logreg, \"Random Forest\": best_rf}\n",
    "    predict_and_evaluate(models, X_test_scaled, y_test)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"Titanic-Dataset.csv\"  # Replace with the actual dataset path\n",
    "    titanic_pipeline(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Repository Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from typing import Tuple, Dict\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_and_preprocess_data(filepath: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Load and preprocess the Titanic dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file containing the Titanic dataset\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.Series]: Preprocessed features (X) and target variable (y)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        logging.info(f\"Loading data from {filepath}\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Handle missing values\n",
    "        df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "        df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "        \n",
    "        # Feature engineering\n",
    "        df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "        df = pd.get_dummies(df, columns=['Embarked'])\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        columns_to_drop = ['Survived', 'Name', 'Ticket', 'PassengerId', 'Cabin']\n",
    "        X = df.drop(columns_to_drop, axis=1)\n",
    "        y = df['Survived']\n",
    "        \n",
    "        logging.info(\"Data preprocessing completed successfully\")\n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data preprocessing: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def train_model(X: pd.DataFrame, y: pd.Series, \n",
    "                hyperparameter_tuning: bool = True) -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Train a Random Forest model with optional hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix\n",
    "        y (pd.Series): Target variable\n",
    "        hyperparameter_tuning (bool): Whether to perform GridSearchCV\n",
    "        \n",
    "    Returns:\n",
    "        RandomForestClassifier: Trained model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"Starting model training\")\n",
    "        \n",
    "        if hyperparameter_tuning:\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4]\n",
    "            }\n",
    "            \n",
    "            model = GridSearchCV(\n",
    "                RandomForestClassifier(random_state=42),\n",
    "                param_grid,\n",
    "                cv=5,\n",
    "                scoring='accuracy'\n",
    "            )\n",
    "            \n",
    "            logging.info(\"Performing hyperparameter tuning\")\n",
    "            model.fit(X, y)\n",
    "            logging.info(f\"Best parameters: {model.best_params_}\")\n",
    "            return model.best_estimator_\n",
    "            \n",
    "        else:\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "            model.fit(X, y)\n",
    "            return model\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in model training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def evaluate_model(model: RandomForestClassifier, X_test: pd.DataFrame, \n",
    "                  y_test: pd.Series) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance.\n",
    "    \n",
    "    Args:\n",
    "        model (RandomForestClassifier): Trained model\n",
    "        X_test (pd.DataFrame): Test features\n",
    "        y_test (pd.Series): Test target\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"Evaluating model performance\")\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Model performance metrics: {metrics}\")\n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in model evaluation: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main(filepath: str):\n",
    "    \"\"\"\n",
    "    Main function to run the complete ML pipeline.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the input dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        X, y = load_and_preprocess_data(filepath)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        trained_model = train_model(X_train, y_train, hyperparameter_tuning=True)\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model(trained_model, X_test, y_test)\n",
    "        \n",
    "        return trained_model, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in pipeline execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"Titanic-Dataset.csv\"\n",
    "    model, metrics = main(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
